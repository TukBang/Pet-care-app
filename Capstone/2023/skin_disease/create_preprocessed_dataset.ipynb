{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TYPE: train\n",
      "\n",
      "original data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "RoI data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "background_RoI data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "box data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "crop data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "ratio_zero-padding data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "RZ_LANCZOS4 data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import pickle as pkl\n",
    "import os\n",
    "import natsort\n",
    "import numpy as np\n",
    "import cv2\n",
    "import module.data_processing as dpc\n",
    "import module.image_preprocessing as ipc\n",
    "\n",
    "TRAIN = 0\n",
    "VALID = 1\n",
    "data_type = [\"train\", \"valid\"]\n",
    "dt = data_type[TRAIN]\n",
    "\n",
    "project_path = \"E:/Tukorea/Capstone/\"\n",
    "original_data_path = os.path.join(project_path, \"dataset/\", \"original/\", f\"{dt}/\")\n",
    "RoI_data_path = os.path.join(project_path, \"dataset/\", \"RoI/\", f\"{dt}/\")\n",
    "background_RoI_data_path = os.path.join(project_path, \"dataset/\", \"background_RoI/\", f\"{dt}/\")\n",
    "box_data_path = os.path.join(project_path, \"dataset/\", \"box/256x256/\", f\"{dt}/\")\n",
    "crop_data_path = os.path.join(project_path, \"dataset/\", \"crop/\", f\"{dt}/\")\n",
    "RZ_data_path = os.path.join(project_path, \"dataset/\", \"ratio_zero-padding/\", f\"{dt}/\")\n",
    "RZ_LANCZOS4_data_path = os.path.join(project_path, \"dataset/\", \"RZ_LANCZOS4/\", f\"{dt}/\")\n",
    "\n",
    "data_path_namelist = [\"original\", \"RoI\", \"background_RoI\", \"box\", \"crop\", \"ratio_zero-padding\", \"RZ_LANCZOS4\"]\n",
    "data_path_list = [original_data_path, RoI_data_path, background_RoI_data_path, box_data_path, crop_data_path, RZ_data_path, RZ_LANCZOS4_data_path]\n",
    "\n",
    "print(\"DATA TYPE:\", dt, end=\"\\n\\n\")\n",
    "for i, data_path in enumerate(data_path_list):\n",
    "    print(data_path_namelist[i] + \" data folder\")\n",
    "    folder = natsort.natsorted(os.listdir(data_path))\n",
    "    print(folder, end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = data_type[VALID]\n",
    "original_data_path = os.path.join(project_path, \"dataset/\", \"original/\", f\"{dt}/\")\n",
    "RoI_data_path = os.path.join(project_path, \"dataset/\", \"RoI/\", f\"{dt}/\")\n",
    "box_data_path = os.path.join(project_path, \"dataset/\", \"box/224x224/\", f\"{dt}/\")\n",
    "crop_data_path = os.path.join(project_path, \"dataset/\", \"crop/\", f\"{dt}/\")\n",
    "RZ_data_path = os.path.join(project_path, \"dataset/\", \"ratio_zero-padding/\", f\"{dt}/\")\n",
    "RZ_LANCZOS4_data_path = os.path.join(project_path, \"dataset/\", \"RZ_LANCZOS4/\", f\"{dt}/\")\n",
    "\n",
    "data_path_namelist = [\"original\", \"RoI\", \"box\", \"crop\", \"ratio_zero-padding\", \"RZ_LANCZOS4\"]\n",
    "data_path_list = [original_data_path, RoI_data_path, box_data_path, crop_data_path, RZ_data_path, RZ_LANCZOS4_data_path]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_folder = os.path.join(project_path, \"dataset/\", \"RoI/\", f\"392-/\", dt) + \"/\"\n",
    "dst_folder = os.path.join(project_path, \"dataset/\", \"RZ_LANCZOS4/\", \"392-/\", f\"{dt}/\")\n",
    "ipc.ratio_resize_and_zeroPadding(224, src_folder, dst_folder, intpol=cv2.INTER_LANCZOS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"392-/\"\n",
    "dst_folder = os.path.join(project_path, \"dataset/\", \"RZ_LANCZOS4/\", fname, f\"{dt}/\")\n",
    "\n",
    "labels = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "label_dict = {\"A1\": 0, \"A2\": 1, \"A3\": 2, \"A4\": 3, \"A5\": 4, \"A6\": 5}\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "for label in labels:\n",
    "    label_path = f\"{dst_folder}{label}/\"\n",
    "    image_names = os.listdir(label_path)\n",
    "\n",
    "    for image_name in image_names:\n",
    "        img = cv2.imread(label_path + image_name)\n",
    "        x.append(img)\n",
    "        y.append(label_dict[label])\n",
    "\n",
    "x = np.array(x)\n",
    "PIL_x = ipc.convert_numpy_to_PIL(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/\".join(dst_folder.split(\"/\")[:-2]) + \"/\"\n",
    "with open(f\"{save_path}{fname[:-1]}_{dt}_data.pkl\", \"wb\") as pkl_file:\n",
    "    pkl.dump((PIL_x, y), pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x, PIL_x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "csv_data_list = list()\n",
    "\n",
    "for label in data_label:\n",
    "    csv_path = f\"{project_path}{label}.csv\"\n",
    "    csv_data = pd.read_csv(csv_path, encoding=\"CP949\")\n",
    "    \n",
    "    # preprocessing\n",
    "    exist_index = csv_data.loc[csv_data[\"exist\"] == \"Y\"].index\n",
    "    csv_data = csv_data.loc[exist_index].copy()\n",
    "    csv_data.drop([\"Unnamed: 0\", \"exist\", \"diagnosis\", \"src_path\", \"label_path\", \"type\", \"fileformat\", \"copyrighter\"], axis=1, inplace=True)\n",
    "    \n",
    "    csv_data_list.append(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "low = 10\n",
    "high = 130\n",
    "dst_folder = os.path.join(project_path, \"dataset/\", \"RoI/\", f\"{low}-{high}/\", dt) + \"/\"\n",
    "\n",
    "for label in data_label:\n",
    "    dpc.mkadir(dst_folder + label + \"/\")\n",
    "\n",
    "for i, csv_data in enumerate(csv_data_list):\n",
    "    filtered_csv = dpc.get_RoI_range_csv(low, high, csv_data)\n",
    "    filtered_img_filenames = list(filtered_csv[\"Raw data ID\"])\n",
    "\n",
    "    src_folder = RoI_data_path + \"/\" + data_label[i] + \"/\"\n",
    "    for filename in filtered_img_filenames:\n",
    "        filename = \"_\".join(filename.split(\"_\")[:3]) + \"_\" + filename.split(\"_\")[-1]\n",
    "    \n",
    "        try:    shutil.copy(src_folder + filename, dst_folder + data_label[i] + \"/\" + filename)\n",
    "        except:\n",
    "            for j in range(5):\n",
    "                new_filename = filename.split(\".\")[0] + f\"T{j}.\" + filename.split(\".\")[1]\n",
    "                temp_img = cv2.imread(src_folder + new_filename)\n",
    "                \n",
    "                if isinstance(temp_img, type(None)):\n",
    "                    continue\n",
    "                \n",
    "                width, height, channel = temp_img.shape\n",
    "                if (width <= 10 or height <= 10):\n",
    "                    continue\n",
    "\n",
    "                try:    shutil.copy(src_folder + new_filename, dst_folder + data_label[i] + \"/\" + new_filename)\n",
    "                except: pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "dt = \"valid\"\n",
    "background_RoI_data_path = os.path.join(project_path, \"dataset/\", \"background_RoI/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/Tukorea/Capstone/dataset/background_RoI/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "background_RoI_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bang\\AppData\\Local\\Temp\\ipykernel_16428\\4290725822.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(x)\n"
     ]
    }
   ],
   "source": [
    "# Load Validation Data\n",
    "labels = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\"]\n",
    "label_dict = {\"A1\": 0, \"A2\": 1, \"A3\": 2, \"A4\": 3, \"A5\": 4}\n",
    "\n",
    "x = list()\n",
    "y = list()\n",
    "filename = \"valid_80p\"\n",
    "for label in labels:\n",
    "    label_path = f\"{background_RoI_data_path}{filename}/{label}/\"\n",
    "    image_names = os.listdir(label_path)\n",
    "\n",
    "    for image_name in image_names:\n",
    "        img = cv2.imread(label_path + image_name)\n",
    "        x.append(img)\n",
    "        y.append(label_dict[label])\n",
    "\n",
    "x = np.array(x)\n",
    "PIL_x = ipc.convert_numpy_to_PIL(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = background_RoI_data_path\n",
    "with open(f\"{save_path}{filename}.pkl\", \"wb\") as pkl_file:\n",
    "    pkl.dump((PIL_x, y), pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
