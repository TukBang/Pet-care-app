{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result (2023-02)\n",
    "    1. 레이블별 해상도 체크: 모두 1920x1080이 아님 \n",
    "    2. 너무 작은 width, height를 가지는 데이터들은 제외됨\n",
    "    3. 관심영역의 크기가 편차가 심함, 256, 384, 512로 먼저 생성\n",
    "        - 이후 그래픽카드 가용 메모리에 따라 조정\n",
    "        - 카메라 구도에 따른 (1)입력 이미지 해상도 축소와 늘리는 방법, (2)제로 패딩 시도 해봐야 함\n",
    "        - 카메라 해상도가 다를 때 사용하는 기술들의 논문 찾기 필요\n",
    "        - 이미지 전처리 방법 적용 방안 (논문 참고)\n",
    "    4. 제외된 이미지들이 있으며, 해당 이미지들은 매우 가까이서 찍은 사진들로 따로 추출이 필요할 수 있음\n",
    "    5. PCA, TSNE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## processing (2023-03-13)\n",
    "1. 레이블별 해상도 이슈 (해상도는 모두 다르기야 하겠지만, 카메라의 구도 문제?)\n",
    "2. 너무 작은 데이터, 너무 큰 데이터의 분포 확인\n",
    "3. 전처리의 방법\n",
    "- resize (보간법 4, 8), transforms.resize\n",
    "- ratio + zero_padding (보간법 4, 8)\n",
    "- 보간법 cubic으로 진행\n",
    "4. pca, tsne를 통해 데이터의 모인 정도를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "from pprint import pprint\n",
    "import natsort\n",
    "import os, sys\n",
    "import json\n",
    "import pickle as pkl\n",
    "from tqdm import notebook\n",
    "\n",
    "# data structure\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# visualize\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# preprocessing\n",
    "import cv2\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = 0\n",
    "VALID = 1\n",
    "data_type = [\"train\", \"valid\"]\n",
    "data_label = [\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"A6\"]\n",
    "\n",
    "project_path = \"D:/Capstone/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_list = list()\n",
    "\n",
    "for label in data_label:\n",
    "    csv_path = f\"{project_path}{label}.csv\"\n",
    "    csv_data = pd.read_csv(csv_path, encoding=\"CP949\")\n",
    "    \n",
    "    # preprocessing\n",
    "    exist_index = csv_data.loc[csv_data[\"exist\"] == \"Y\"].index\n",
    "    csv_data = csv_data.loc[exist_index].copy()\n",
    "    csv_data.drop([\"Unnamed: 0\", \"exist\", \"diagnosis\", \"src_path\", \"label_path\", \"type\", \"fileformat\", \"copyrighter\"], axis=1, inplace=True)\n",
    "    \n",
    "    csv_data_list.append(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
