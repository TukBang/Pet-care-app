{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA TYPE: train\n",
      "\n",
      "original data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "RoI data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "box data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "crop data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "ratio_zero-padding data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n",
      "RZ_LANCZOS4 data folder\n",
      "['A1', 'A2', 'A3', 'A4', 'A5', 'A6']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# default\n",
    "from pprint import pprint\n",
    "import natsort\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "# data structure\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchinfo import summary\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.models import efficientnet_v2_s, efficientnet_v2_m, efficientnet_v2_l\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import module.skin_disease_model as sdm\n",
    "from module.data_processing import mkadir\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TRAIN = 0\n",
    "VALID = 1\n",
    "data_type = [\"train\", \"valid\"]\n",
    "dt = data_type[TRAIN]\n",
    "\n",
    "project_path = \"E:/Tukorea/Capstone/\"\n",
    "original_data_path = os.path.join(project_path, \"dataset/\", \"original/\", dt)\n",
    "RoI_data_path = os.path.join(project_path, \"dataset/\", \"RoI/\", dt)\n",
    "box_data_path = os.path.join(project_path, \"dataset/\", \"box/256x256/\", dt)\n",
    "crop_data_path = os.path.join(project_path, \"dataset/\", \"crop/\", dt)\n",
    "RZ_data_path = os.path.join(project_path, \"dataset/\", \"ratio_zero-padding/\", dt)\n",
    "RZ_LANCZOS4_data_path = os.path.join(project_path, \"dataset/\", \"RZ_LANCZOS4/\", dt)\n",
    "\n",
    "data_path_namelist = [\"original\", \"RoI\", \"box\", \"crop\", \"ratio_zero-padding\", \"RZ_LANCZOS4\"]\n",
    "data_path_list = [original_data_path, RoI_data_path, box_data_path, crop_data_path, RZ_data_path, RZ_LANCZOS4_data_path]\n",
    "\n",
    "print(\"DATA TYPE:\", dt, end=\"\\n\\n\")\n",
    "for i, data_path in enumerate(data_path_list):\n",
    "    print(data_path_namelist[i] + \" data folder\")\n",
    "    folder = natsort.natsorted(os.listdir(data_path))\n",
    "    print(folder, end=\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x length:  53430\n",
      "train_x type:  <class 'list'>\n",
      "train_y length:  (53430,)\n",
      "train_y type:  <class 'numpy.ndarray'>\n",
      "valid_x length:  6645\n",
      "valid_x type:  <class 'list'>\n",
      "valid_y length:  (6645,)\n",
      "valid_y type:  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "size = 224\n",
    "dataset_path = \"/\".join(RZ_LANCZOS4_data_path.split(\"/\")[:-1]) + \"/\"\n",
    "\n",
    "# 이미지 불러오기\n",
    "with open(os.path.join(dataset_path, \"224x224_train_data.pkl\"), \"rb\") as pkl_file:\n",
    "  train_x, train_y = pkl.load(pkl_file)\n",
    "\n",
    "with open(os.path.join(dataset_path, \"224x224_valid_data.pkl\"), \"rb\") as pkl_file:\n",
    "  valid_x, valid_y = pkl.load(pkl_file)\n",
    "\n",
    "print(\"train_x length: \", len(train_x))\n",
    "print(\"train_x type: \", type(train_x))\n",
    "print(\"train_y length: \", train_y.shape)\n",
    "print(\"train_y type: \", type(train_y))\n",
    "print(\"valid_x length: \", len(valid_x))\n",
    "print(\"valid_x type: \", type(valid_x))\n",
    "print(\"valid_y length: \", valid_y.shape)\n",
    "print(\"valid_y type: \", type(valid_y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = sdm.Skin_Disease_Dataset(train_x, train_y, train_transforms)\n",
    "valid_dataset = sdm.Skin_Disease_Dataset(valid_x, valid_y, test_transforms)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "valid_data_loader = DataLoader(valid_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================================================================\n",
      "Layer (type:depth-idx)                                       Output Shape              Param #\n",
      "==============================================================================================================\n",
      "Skin_Distinction_Model                                       [1, 6]                    --\n",
      "├─EfficientNet: 1-1                                          [1, 1000]                 --\n",
      "│    └─Sequential: 2-1                                       [1, 1280, 7, 7]           --\n",
      "│    │    └─Conv2dNormActivation: 3-1                        [1, 24, 112, 112]         696\n",
      "│    │    └─Sequential: 3-2                                  [1, 24, 112, 112]         10,464\n",
      "│    │    └─Sequential: 3-3                                  [1, 48, 56, 56]           303,552\n",
      "│    │    └─Sequential: 3-4                                  [1, 64, 28, 28]           589,184\n",
      "│    │    └─Sequential: 3-5                                  [1, 128, 14, 14]          917,680\n",
      "│    │    └─Sequential: 3-6                                  [1, 160, 14, 14]          3,463,840\n",
      "│    │    └─Sequential: 3-7                                  [1, 256, 7, 7]            14,561,832\n",
      "│    │    └─Conv2dNormActivation: 3-8                        [1, 1280, 7, 7]           330,240\n",
      "│    └─AdaptiveAvgPool2d: 2-2                                [1, 1280, 1, 1]           --\n",
      "│    └─Sequential: 2-3                                       [1, 1000]                 --\n",
      "│    │    └─Dropout: 3-9                                     [1, 1280]                 --\n",
      "│    │    └─Linear: 3-10                                     [1, 1000]                 1,281,000\n",
      "├─Linear: 1-2                                                [1, 6]                    6,006\n",
      "==============================================================================================================\n",
      "Total params: 21,464,494\n",
      "Trainable params: 21,464,494\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.85\n",
      "==============================================================================================================\n",
      "Input size (MB): 0.60\n",
      "Forward/backward pass size (MB): 194.82\n",
      "Params size (MB): 85.86\n",
      "Estimated Total Size (MB): 281.28\n",
      "==============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(project_path, \"model/\", \"2023-03-16/\")\n",
    "mkadir(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = sdm.Skin_Distinction_Model(model=efficientnet_v2_s(weights=\"DEFAULT\"),\n",
    "                                   out_features=6,\n",
    "                                   device=device,\n",
    "                                   save_path=model_path).to(device)\n",
    "\n",
    "pprint(summary(model, input_size=(1, 3, 224, 224), verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.000213388\n",
    "# optimizer = optim.SGD(model.parameters(), lr=7.5e-7, momentum=0.999, weight_decay=1e-5, nesterov=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "parameters = {\n",
    "    'Train_DataLoader' : train_data_loader,\n",
    "    'Valid_DataLoader' : valid_data_loader,\n",
    "    'Optimizer'        : optimizer,\n",
    "    'Loss_function'    : criterion,\n",
    "    'Epochs'           : epochs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72b57166ac244a0f8aa495e769f56823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
